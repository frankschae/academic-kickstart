---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Machine Learning for Phase Transitions"
summary: "Data-driven methods based on sample instances of the state of a physical system as a function of the system's parameters."
authors: [FS in collaboration with Julian Arnold, Eliska Greplova, Agnes Valenti, Martin Zonda, Axel Lode, Gregor Boschung, Sebastian Huber, and Niels LÃ¶rch]
tags: [Machine learning, analytical predictors, neural networks, unsupervised learning]
categories: []
date: 2021-03-09T23:56:43+01:00

# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: Smart
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_code: "https://github.com/arnoldjulian/Replacing-neural-networks-by-optimal-analytical-predictors-for-the-detection-of-phase-transitions"
url_pdf: ""
url_slides: ""
url_video: ""

links:
- name: PRE
  url: "https://journals.aps.org/pre/abstract/10.1103/PhysRevE.99.062107"
- name: NJP
  url: "https://iopscience.iop.org/article/10.1088/1367-2630/ab7771/meta"
- name: PRResearch
  url: "https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.3.033052"
- name: PRX
  url: "https://journals.aps.org/prx/abstract/10.1103/PhysRevX.12.031044"

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

 Artificial neural networks have successfully been used to identify phase transitions from data and classify data into distinct phases in an automated fashion. The power and success of these approaches (e.g., "learning by confusion" or the "prediction-based method") can be attributed to the ability of deep neural networks to learn arbitrary functions. However, the larger a neural network, the more computational resources are needed to train it, and the more difficult it is to understand its decision making. In this project, we establish a solid theoretical foundation of popular machine-learning methods that rely on neural networks for detecting phase transitions and develop new efficient numerical routines to identify phase transitions directly from data. In the future, our methods could make it possible to detect as yet unknown phase transitions, for instance in quantum simulators or in novel materials.
